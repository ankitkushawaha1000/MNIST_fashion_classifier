{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D,Dropout,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "%matplotlib inline\n",
    "# tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.astype('float32')/255\n",
    "test_x = test_x.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
       "        0.4627451 , 0.09411765, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1882353 , 0.34509805, 0.01960784,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.04705882, 0.39215687,\n",
       "        0.83137256, 0.8039216 , 0.7254902 , 0.7019608 , 0.6784314 ,\n",
       "        0.7294118 , 0.75686276, 0.8666667 , 0.5568628 , 0.33333334,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.33333334,\n",
       "        0.29803923, 0.78039217, 0.88235295, 0.972549  , 1.        ,\n",
       "        0.93333334, 0.8862745 , 0.6156863 , 0.26666668, 0.3137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.35686275,\n",
       "        0.27058825, 0.35686275, 0.7882353 , 0.85490197, 0.88235295,\n",
       "        0.81960785, 0.61960787, 0.23921569, 0.3647059 , 0.28235295,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.30980393,\n",
       "        0.34901962, 0.23921569, 0.23137255, 0.34117648, 0.42352942,\n",
       "        0.29411766, 0.21960784, 0.29803923, 0.38039216, 0.28627452,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "        0.34901962, 0.3137255 , 0.3137255 , 0.2627451 , 0.24705882,\n",
       "        0.28627452, 0.3254902 , 0.3137255 , 0.3764706 , 0.28235295,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.3019608 ,\n",
       "        0.34509805, 0.3019608 , 0.3137255 , 0.3254902 , 0.3254902 ,\n",
       "        0.3254902 , 0.3254902 , 0.31764707, 0.37254903, 0.29803923,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.34901962,\n",
       "        0.3764706 , 0.3137255 , 0.3254902 , 0.31764707, 0.32941177,\n",
       "        0.33333334, 0.33333334, 0.33333334, 0.38039216, 0.32941177,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.3647059 ,\n",
       "        0.38039216, 0.31764707, 0.33333334, 0.32941177, 0.33333334,\n",
       "        0.34117648, 0.34509805, 0.32941177, 0.3882353 , 0.34117648,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.37254903,\n",
       "        0.34117648, 0.32941177, 0.34117648, 0.34509805, 0.33333334,\n",
       "        0.34117648, 0.34117648, 0.32941177, 0.36078432, 0.34117648,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.38039216,\n",
       "        0.34117648, 0.34117648, 0.33333334, 0.34509805, 0.34117648,\n",
       "        0.34117648, 0.34117648, 0.34509805, 0.33333334, 0.41960785,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.06666667, 0.39215687,\n",
       "        0.34509805, 0.34117648, 0.34117648, 0.34509805, 0.34117648,\n",
       "        0.34117648, 0.33333334, 0.34901962, 0.3019608 , 0.4627451 ,\n",
       "        0.03137255, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03921569, 0.3647059 ,\n",
       "        0.34117648, 0.34117648, 0.34117648, 0.34117648, 0.34117648,\n",
       "        0.34509805, 0.34117648, 0.34901962, 0.3137255 , 0.40392157,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03529412, 0.3764706 ,\n",
       "        0.34117648, 0.34117648, 0.34117648, 0.34117648, 0.34117648,\n",
       "        0.34509805, 0.34117648, 0.34509805, 0.34117648, 0.40392157,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.04705882, 0.3764706 ,\n",
       "        0.33333334, 0.34117648, 0.34117648, 0.34117648, 0.33333334,\n",
       "        0.34117648, 0.34117648, 0.34509805, 0.34901962, 0.39215687,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.07843138, 0.37254903,\n",
       "        0.32941177, 0.34509805, 0.33333334, 0.34117648, 0.34509805,\n",
       "        0.34509805, 0.34509805, 0.34901962, 0.34509805, 0.3882353 ,\n",
       "        0.03137255, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.08235294, 0.3764706 ,\n",
       "        0.33333334, 0.34117648, 0.33333334, 0.34509805, 0.34509805,\n",
       "        0.34509805, 0.34509805, 0.34901962, 0.34901962, 0.3882353 ,\n",
       "        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09411765, 0.3764706 ,\n",
       "        0.33333334, 0.34117648, 0.33333334, 0.34117648, 0.34509805,\n",
       "        0.34509805, 0.34901962, 0.34509805, 0.35686275, 0.4       ,\n",
       "        0.05490196, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09803922, 0.3647059 ,\n",
       "        0.32941177, 0.34509805, 0.34117648, 0.34117648, 0.34117648,\n",
       "        0.34117648, 0.34117648, 0.34901962, 0.35686275, 0.40392157,\n",
       "        0.11372549, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.37254903,\n",
       "        0.33333334, 0.34509805, 0.34509805, 0.34117648, 0.34117648,\n",
       "        0.34117648, 0.34117648, 0.34901962, 0.34509805, 0.4       ,\n",
       "        0.14509805, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.13333334, 0.3764706 ,\n",
       "        0.34509805, 0.34117648, 0.34117648, 0.34117648, 0.34117648,\n",
       "        0.34117648, 0.34117648, 0.33333334, 0.33333334, 0.38039216,\n",
       "        0.14901961, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.15686275, 0.3764706 ,\n",
       "        0.34117648, 0.33333334, 0.34117648, 0.34117648, 0.34117648,\n",
       "        0.34117648, 0.34117648, 0.33333334, 0.32941177, 0.36078432,\n",
       "        0.19215687, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18039216, 0.37254903,\n",
       "        0.3254902 , 0.32941177, 0.34117648, 0.34117648, 0.34117648,\n",
       "        0.34117648, 0.34117648, 0.34117648, 0.32941177, 0.34117648,\n",
       "        0.32941177, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.28235295, 0.37254903,\n",
       "        0.33333334, 0.32941177, 0.33333334, 0.34509805, 0.34117648,\n",
       "        0.34117648, 0.34901962, 0.34117648, 0.33333334, 0.3254902 ,\n",
       "        0.24705882, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.2509804 , 0.39215687,\n",
       "        0.32941177, 0.34117648, 0.34509805, 0.33333334, 0.34509805,\n",
       "        0.34509805, 0.32941177, 0.34117648, 0.3254902 , 0.37254903,\n",
       "        0.20784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03921569, 0.4       ,\n",
       "        0.39215687, 0.35686275, 0.35686275, 0.34901962, 0.33333334,\n",
       "        0.32941177, 0.32941177, 0.34117648, 0.42352942, 0.41568628,\n",
       "        0.05490196, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.03137255,\n",
       "        0.28627452, 0.3647059 , 0.40784314, 0.41960785, 0.40392157,\n",
       "        0.40392157, 0.41568628, 0.4       , 0.29411766, 0.03921569,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.16470589, 0.22352941,\n",
       "        0.21960784, 0.1254902 , 0.03137255, 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_labels = [\"T-shirt/top\",  \n",
    "                        \"Trouser\",      \n",
    "                        \"Pullover\",      \n",
    "                        \"Dress\",         \n",
    "                        \"Coat\",         \n",
    "                        \"Sandal\",       \n",
    "                        \"Shirt\",        \n",
    "                        \"Sneaker\",    \n",
    "                        \"Bag\",           \n",
    "                        \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trouser\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2401594f8b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 143\n",
    "print(fashion_mnist_labels[train_y[index]])\n",
    "plt.imshow(train_x[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,val_x = train_x[:55000],train_x[55000:]\n",
    "train_y,val_y = train_y[:55000],train_y[55000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(len(train_x),28,28,1)\n",
    "test_x =test_x.reshape(len(test_x),28,28,1)\n",
    "val_x = val_x.reshape(len(val_x),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_y,10)\n",
    "val_y = to_categorical(val_y,10)\n",
    "test_y = to_categorical(test_y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters = 64,kernel_size=2,padding='same',activation='relu',input_shape=(28,28,1)),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(filters=64,kernel_size=2,padding='same',activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 822,410\n",
      "Trainable params: 822,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "optimizer = 'adam',\n",
    "loss = 'categorical_crossentropy',\n",
    "metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath = 'model.weights.best.hdf5',verbose = 1,save_best_only = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 90s 102ms/step - loss: 0.7589 - accuracy: 0.7190 - val_loss: 0.3672 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36724, saving model to model.weights.best.hdf5\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 84s 98ms/step - loss: 0.4018 - accuracy: 0.8536 - val_loss: 0.3019 - val_accuracy: 0.8892\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.36724 to 0.30187, saving model to model.weights.best.hdf5\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 83s 97ms/step - loss: 0.3455 - accuracy: 0.8773 - val_loss: 0.2845 - val_accuracy: 0.8924\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.30187 to 0.28449, saving model to model.weights.best.hdf5\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 85s 99ms/step - loss: 0.3115 - accuracy: 0.8853 - val_loss: 0.2633 - val_accuracy: 0.9016\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28449 to 0.26329, saving model to model.weights.best.hdf5\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 86s 100ms/step - loss: 0.2930 - accuracy: 0.8936 - val_loss: 0.2502 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.26329 to 0.25016, saving model to model.weights.best.hdf5\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 87s 101ms/step - loss: 0.2766 - accuracy: 0.8985 - val_loss: 0.2405 - val_accuracy: 0.9120\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.25016 to 0.24054, saving model to model.weights.best.hdf5\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 86s 100ms/step - loss: 0.2648 - accuracy: 0.9024 - val_loss: 0.2342 - val_accuracy: 0.9100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.24054 to 0.23418, saving model to model.weights.best.hdf5\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 87s 101ms/step - loss: 0.2587 - accuracy: 0.9066 - val_loss: 0.2208 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.23418 to 0.22082, saving model to model.weights.best.hdf5\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 86s 100ms/step - loss: 0.2424 - accuracy: 0.9120 - val_loss: 0.2183 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.22082 to 0.21835, saving model to model.weights.best.hdf5\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 84s 98ms/step - loss: 0.2367 - accuracy: 0.9131 - val_loss: 0.2240 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.21835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24017f20e20>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y,batch_size = 64,epochs=10,\n",
    "          validation_data=(val_x,val_y),\n",
    "         callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x,test_y,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy :  0.9150000214576721\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy : \",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MNIST_fashion_classifier_CNN\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('MNIST_fashion_classifier_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
